{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ahmedmalaa/evaluating-generative-models/blob/boris/toy_metric_evaluation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GXIxQpZzbR0p",
    "outputId": "87f24cff-82b4-40fb-aa2d-14713c75cb4a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fuYbSIGRbZxZ",
    "outputId": "41e7fe34-515f-4db4-9d9a-4c18f431ef4f"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RpK5ONyoWyGb"
   },
   "source": [
    "# Function imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ah86L26QbS8l"
   },
   "outputs": [],
   "source": [
    "from metrics.prdc import compute_prdc\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "from representations.OneClass import * \n",
    "from metrics.evaluation import *\n",
    "\n",
    "nearest_k = 5\n",
    "params  = dict({\"rep_dim\": None, \n",
    "                \"num_layers\": 2, \n",
    "                \"num_hidden\": 200, \n",
    "                \"activation\": \"ReLU\",\n",
    "                \"dropout_prob\": 0.5, \n",
    "                \"dropout_active\": False,\n",
    "                \"train_prop\" : 1,\n",
    "                \"epochs\" : 100,\n",
    "                \"warm_up_epochs\" : 10,\n",
    "                \"lr\" : 1e-3,\n",
    "                \"weight_decay\" : 1e-2,\n",
    "                \"LossFn\": \"SoftBoundary\"})   \n",
    "\n",
    "hyperparams = dict({\"Radius\": 1, \"nu\": 1e-2})\n",
    "\n",
    "\n",
    "\n",
    "def plot_all(x, res, x_axis):\n",
    "    print(x_axis)\n",
    "    if type(res) == type([]):\n",
    "        plot_legend = False\n",
    "        res = {'0':res}\n",
    "    else:\n",
    "        plot_legend = True\n",
    "    exp_keys = list(res.keys())\n",
    "    print(res)\n",
    "    metric_keys = res[exp_keys[0]][0].keys() \n",
    "    for m_key in metric_keys:\n",
    "        for e_key in exp_keys:\n",
    "          y = [res[e_key][i][m_key] for i in range(len(x))]\n",
    "          plt.plot(x, y, label=e_key)\n",
    "        \n",
    "        plt.ylabel(m_key)\n",
    "        plt.ylim(bottom=0)\n",
    "        plt.xlabel(x_axis) \n",
    "        if plot_legend:\n",
    "            plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def compute_metrics(X,Y, nearest_k = 5, model = None):\n",
    "    results = compute_prdc(X,Y, nearest_k)\n",
    "    if model is None:\n",
    "        #these are fairly arbitrarily chosen\n",
    "        params[\"input_dim\"] = X.shape[1]\n",
    "        params[\"rep_dim\"] = X.shape[1]        \n",
    "        hyperparams[\"center\"] = torch.ones(X.shape[1])\n",
    "        \n",
    "        model = OneClassLayer(params=params, hyperparams=hyperparams)\n",
    "         \n",
    "        model.fit(X,verbosity=False)\n",
    "\n",
    "    X_out = model(torch.tensor(X).float()).float().detach().numpy()\n",
    "    Y_out = model(torch.tensor(Y).float()).float().detach().numpy()\n",
    "    \n",
    "    alphas, alpha_precision_curve, beta_coverage_curve, Delta_precision_alpha, Delta_coverage_beta, (thresholds, authen) = compute_alpha_precision(X_out, Y_out, model.c)\n",
    "    results['Dpa'] = Delta_precision_alpha\n",
    "    results['Dcb'] = Delta_coverage_beta\n",
    "    results['mean_aut'] = np.mean(authen)\n",
    "    return results, model\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KmYVc43kaA3w"
   },
   "source": [
    "In all experiments, X denotes original data and Y synthetic data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JQrotH8mXXyF"
   },
   "source": [
    "# Translation\n",
    "Three experiments\n",
    "\n",
    "\n",
    "\n",
    "1.   $X \\sim N(0,I)$, \n",
    "$Y \\sim N(\\mu,I)$\n",
    "2.   Same as 1. but with one outlier in Y at (1,1,...,1)\n",
    "3.   Same as 1. but with one outlier in X at (1,1,...,1)\n",
    "\n",
    "\n",
    "Precision recall is not robust to outliers, even if it's just a single outlier.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "gH2N3LVuJjYd",
    "outputId": "65436bde-d7a5-4f32-dc19-9475cc3cbb9b"
   },
   "outputs": [],
   "source": [
    "def translation_test(d=64, n=1000, step_size=0.1):\n",
    "    X = np.random.randn(n,d)\n",
    "    Y_0 = np.random.randn(n,d)\n",
    "\n",
    "    X_outlier = X.copy()\n",
    "    X_outlier[-1] = np.ones(d)\n",
    "\n",
    "    res = []\n",
    "    res_outr = []\n",
    "    res_outf = []\n",
    "\n",
    "    # translation\n",
    "    mus = np.arange(-1,1+step_size,step_size)\n",
    "    model = None\n",
    "    for i, mu in enumerate(mus):\n",
    "        Y = Y_0 + mu\n",
    "        res_, model = compute_metrics(X,Y, model=model)\n",
    "        res.append(res_)\n",
    "\n",
    "    model = None\n",
    "    for i, mu in enumerate(mus):\n",
    "        Y = Y_0 + mu\n",
    "        res_, model = compute_metrics(X_outlier,Y, model=model)\n",
    "        res_outr.append(res_)    \n",
    "    \n",
    "    model = None\n",
    "    for i, mu in enumerate(mus):\n",
    "        Y_outlier = Y_0 + mu\n",
    "        Y_outlier[-1] = np.ones(d)\n",
    "        res_, model = compute_metrics(X, Y_outlier, model = model)\n",
    "        res_outf.append(res_)\n",
    "\n",
    "    res = {'No outlier':res, 'Real outlier':res_outr, 'Fake outlier':res_outf}\n",
    "    plot_all(mus, res, r'$\\mu$')\n",
    "\n",
    "\n",
    "translation_test(n=10000, d=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Rr_o19XYZsF6"
   },
   "source": [
    "# Mode dropping\n",
    "X is mixture of Gaussian nodes. For Y, all nodes except zeroth are dropped slowly. Either simultaneously (all nodes except zeroth node are dropped), or sequentially. \n",
    "\n",
    "$\\Delta P_\\alpha$ is better than benchmarks, as it decreases steadier and is thus more sensitive to small imbalances in mode generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "s2n6qOu2JlC3",
    "outputId": "beca2a02-6f11-4401-854b-1ebb5ee2dcdf"
   },
   "outputs": [],
   "source": [
    "def mode_drop_test(n=1000, d=1, num_nodes=10, dist_between_nodes=4):\n",
    "    \n",
    "    # random assignment\n",
    "    assignment = np.floor(np.random.rand(n)*num_nodes)\n",
    "    means = np.zeros((n,d))\n",
    "    means[:,0] = assignment * dist_between_nodes\n",
    "    X = np.random.randn(n,d) + means\n",
    "    Y_0 = np.random.randn(n,d)\n",
    "\n",
    "    res_md_sim = []\n",
    "    step_size = 0.04\n",
    "    \n",
    "    #simultaneous dropping\n",
    "    p_mode_drops = np.arange(0,1+step_size,step_size)\n",
    "    model = None\n",
    "\n",
    "    assignment_Y_ = np.floor(np.random.rand(n)*num_nodes)\n",
    "\n",
    "    for p_mode_drop in p_mode_drops:\n",
    "        mode_drop = np.random.rand(n)<p_mode_drop\n",
    "        # if mode_drop, assign to first Gaussian\n",
    "        assignment_Y = assignment_Y_ * (1-mode_drop)\n",
    "        means = np.zeros((n,d))\n",
    "        means[:,0] = assignment_Y * dist_between_nodes\n",
    "        Y = Y_0 + means\n",
    "        res_, model = compute_metrics(X,Y, model=model)\n",
    "        res_md_sim.append(res_)\n",
    " \n",
    "    # sequential dropping    \n",
    "    res_md_seq = []\n",
    "    \n",
    "    assignment_Y = np.sort(np.floor(np.random.rand(n)*num_nodes))\n",
    "    len_nonzero = (assignment_Y != 0).sum()\n",
    "    \n",
    "    for p_mode_drop in p_mode_drops:\n",
    "         if p_mode_drop>1e-8:\n",
    "           assignment_Y[-round(len_nonzero*p_mode_drop):] = 0\n",
    "         \n",
    "         means = np.zeros((n,d))\n",
    "         means[:,0] = assignment_Y * dist_between_nodes\n",
    "         Y = Y_0 + means\n",
    "         res_, _ = compute_metrics(X,Y,model=model)\n",
    "         res_md_seq.append(res_)\n",
    "    \n",
    "    print(X.dtype, Y.dtype)\n",
    "    res = {}\n",
    "    res['Simultaneous'] = res_md_sim\n",
    "    res['Sequential'] = res_md_seq\n",
    "    plot_all(p_mode_drops, res, r'p')\n",
    "\n",
    "mode_drop_test(n=10000, d=1, num_nodes=10, dist_between_nodes = 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ktjb2SU_Z2z0"
   },
   "source": [
    "# Mode resolution\n",
    "X consists of a mixture of standard Gaussians at $\\pm 0.5\\mu$, Y is a Gaussian with the same variance as $X$ centred at 0. This tests whether the metric can distinguish different modes well, i.e. two modes in the original data vs one mode in the synthetic data.\n",
    "\n",
    "Both $\\Delta P_\\alpha$ and $\\Delta C_\\beta$ go down quicker than the other metrics, which means the metric has a higher resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "THkp1lMdJl91",
    "outputId": "d78a455f-22e4-42e5-d156-5827b9bfba95"
   },
   "outputs": [],
   "source": [
    "def mode_resolution_test(n=1000,d=1):\n",
    "    step_size = 0.1\n",
    "    dists = np.arange(0,5+step_size,step_size)\n",
    "    res_resolution = []\n",
    "    for dist in dists:\n",
    "        mus = dist*((np.random.rand(n)>0.5)-0.5)\n",
    "        X = ((np.random.randn(n,d)).T + mus).T\n",
    "        std = np.std(X,axis=0)\n",
    "        Y = std * np.random.randn(n,d)\n",
    "        res_, _ = compute_metrics(X,Y, model=None)\n",
    "        res_resolution.append(res_)\n",
    "      # mode resolution\n",
    "\n",
    "    plot_all(dists, res_resolution, 'distance')\n",
    "\n",
    "mode_resolution_test(n=10000,d=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opaUvkueZeB3"
   },
   "source": [
    "# Variance test\n",
    "$X\\sim N(0,I)$\n",
    "\n",
    "$Y\\sim (N0, \\sigma I)$\n",
    "\n",
    "$\\Delta P_\\alpha$ shows the clearest peak at $\\sigma=1$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DNscKEpPTl5g",
    "outputId": "77cd6cc0-7bae-4ad6-dcb7-8d74ef894bcf"
   },
   "outputs": [],
   "source": [
    "def variance_test(n=1000, d=64):\n",
    "    X = np.random.randn(n,d)\n",
    "    step_size = 0.05\n",
    "    stds = np.arange(0,2+step_size,step_size)#np.exp(np.arange(-2,1,step_size))\n",
    "    res = []\n",
    "    model = None\n",
    "    for std in stds:\n",
    "        Y = np.random.randn(n,d)*std\n",
    "        res_, model = compute_metrics(X,Y, model=model)\n",
    "        res.append(res_)\n",
    "    \n",
    "    plot_all(stds, res, 'std')\n",
    "    \n",
    "variance_test(n=10000, d=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8dzavksTZinB"
   },
   "source": [
    "# Outlier proportion\n",
    "Metrics as a funtion of outliers.\n",
    "X standard normal, Y contain $p_{out}$ proportion of outlier points (defined as points on the hypersphere with radius 5).\n",
    "\n",
    "Our metrics don't do too well on this test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FG3uUgnaTm8t",
    "outputId": "a470b3bc-ca75-4775-dba6-e4473a1723e6"
   },
   "outputs": [],
   "source": [
    "def outlier_proportion_test(n=1000, d=64):\n",
    "    X = np.random.randn(n,d)\n",
    "    X_outlier = np.random.randn(n,d)\n",
    "    X_outlier = (X_outlier.T/np.sum(X_outlier**2,axis=1)).T*5\n",
    "    \n",
    "    Y = np.random.randn(n,d)\n",
    "    Y_outlier = np.random.randn(n,d)\n",
    "    Y_outlier = (Y_outlier.T/np.sum(Y_outlier**2,axis=1)).T *5\n",
    "    \n",
    "    \n",
    "    res_outr = []\n",
    "    res_outf = []\n",
    "\n",
    "    # Outlier proportion\n",
    "    step_size = 0.02\n",
    "    p_outlier = np.arange(0,0.5+step_size,step_size)\n",
    "    model = None\n",
    "\n",
    "    for p in p_outlier:\n",
    "        c = int(p*n)\n",
    "        X_p = np.concatenate((X_outlier[:c],X[c:]),axis=0)\n",
    "        res_, _ = compute_metrics(X_p, Y)\n",
    "        res_outr.append(res_)    \n",
    "\n",
    "    for p in p_outlier:\n",
    "        c = int(p*n)\n",
    "        Y_p = np.concatenate((Y_outlier[:c],Y[c:]),axis=0)\n",
    "        res_, model = compute_metrics(X, Y, model=model)\n",
    "        res_outf.append(res_)    \n",
    "        \n",
    "    res = {'Real outliers':res_outr, 'Fake outliers':res_outf}\n",
    "    plot_all(p_outlier, res, r'$p_{out}$') \n",
    "    \n",
    "\n",
    "outlier_proportion_test(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZKJUAZC0Tqhm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TYAlMoF-m-B"
   },
   "source": [
    "# Autenticity test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "reo_GcEpFJYN"
   },
   "source": [
    "Test in which proportion of original data is exactly included in synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "vy7c7Zp7-o34",
    "outputId": "11a28500-33c4-4be2-adb1-24ba12884349"
   },
   "outputs": [],
   "source": [
    "def copy_test(n=1000, d=64):\n",
    "    X = np.random.randn(n,d)\n",
    "    Y = np.random.randn(n,d)\n",
    "    \n",
    "    # Copied proportion\n",
    "    step_size = 0.1\n",
    "    p_copied = np.arange(0,1+step_size,step_size)\n",
    "    \n",
    "    model = None\n",
    "    res = []\n",
    "\n",
    "    for p in p_copied:\n",
    "        c = int(p*n)\n",
    "        Y_p = np.concatenate((X[:c],Y[c:]),axis=0)\n",
    "        res_, model = compute_metrics(X, Y, model=model)\n",
    "        res.append(res_)    \n",
    "        \n",
    "    res = {'autenticity':res}\n",
    "    plot_all(p_copied, res, r'$p_{copied}$') \n",
    "\n",
    "\n",
    "\n",
    "copy_test(n=10000, d=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dOxJ6Z5pALwr"
   },
   "source": [
    "Test in which all data is copied but random noise is added of different levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "IEkCixxsAL8h"
   },
   "outputs": [],
   "source": [
    "def copy_with_noise_test(n=1000, d=64):\n",
    "    X = np.random.randn(n,d)\n",
    "    \n",
    "    # Outlier proportion\n",
    "    step_size = 0.1\n",
    "    noise_level = np.arange(0,1+step_size,step_size)\n",
    "    \n",
    "    model = None\n",
    "    res = []\n",
    "\n",
    "    for std in noise_levels:\n",
    "        Y = X +np.random.randn(n,d,) * std\n",
    "        res_, model = compute_metrics(X, Y, model=model)\n",
    "        res.append(res_)    \n",
    "        \n",
    "    res = {'autenticity':res}\n",
    "    plot_all(noise_levels, res, r'$std_noise$') \n",
    "\n",
    "copy_with_noise_test(n=10000, d=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9DIEMg_NDtqs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPO0UODjI2LNnb0cX8iU02N",
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "toy_metric_evaluation.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
